"""
This type stub file was generated by pyright.
"""

import abc
import numpy as np
from collections.abc import Sequence
from enum import Enum
from pathlib import Path
from onnx import ModelProto

def rel_entr(pk: np.ndarray, qk: np.ndarray) -> np.ndarray:
    """
    See https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr.
    Python implementation.
    """
    ...

def entropy(pk: np.ndarray, qk: np.ndarray, base: float | None = ..., axis: int = ...) -> np.ndarray:
    """
    Simplifeied version of entropy.
    Source: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html.
    This avoids taking a dependency on scipy just for this function.
    """
    ...

class TensorData:
    _allowed = ...
    _floats = ...
    def __init__(self, **kwargs) -> None:
        ...
    
    @property
    def range_value(self): # -> tuple[Any, Any]:
        ...
    
    @property
    def avg_std(self): # -> tuple[Any, Any]:
        ...
    
    def to_dict(self): # -> dict[str, Any]:
        ...
    


class TensorsData:
    def __init__(self, calibration_method, data: dict[str, TensorData | tuple]) -> None:
        ...
    
    def __iter__(self): # -> Generator[Any, Any, None]:
        ...
    
    def __contains__(self, key): # -> bool:
        ...
    
    def __getitem__(self, key):
        ...
    
    def __setitem__(self, key, value): # -> None:
        ...
    
    def keys(self): # -> dict_keys[Any, Any]:
        ...
    
    def values(self): # -> dict_values[Any, Any]:
        ...
    
    def items(self): # -> dict_items[Any, Any]:
        ...
    
    def to_dict(self): # -> dict[str, str | Any | dict[Any, Any]]:
        ...
    


class CalibrationMethod(Enum):
    MinMax = ...
    Entropy = ...
    Percentile = ...
    Distribution = ...


class CalibrationDataReader(metaclass=abc.ABCMeta):
    @classmethod
    def __subclasshook__(cls, subclass): # -> TypeIs[Callable[..., object]] | _NotImplementedType:
        ...
    
    @abc.abstractmethod
    def get_next(self) -> dict:
        """generate the input data dict for ONNXinferenceSession run"""
        ...
    
    def __iter__(self): # -> Self:
        ...
    
    def __next__(self): # -> dict[Any, Any]:
        ...
    
    def __len__(self):
        ...
    
    def set_range(self, start_index: int, end_index: int):
        ...
    


class CalibraterBase:
    def __init__(self, model_path: str | Path, op_types_to_calibrate: Sequence[str] | None = ..., augmented_model_path=..., symmetric=..., use_external_data_format=..., per_channel=...) -> None:
        """
        :param model_path: ONNX model to calibrate. It should be a model file path
        :param op_types_to_calibrate: operator types to calibrate. By default, calibrate all the float32/float16 tensors.
        :param augmented_model_path: save augmented model to this path.
        :param symmetric: make range of tensor symmetric (central point is 0).
        :param use_external_data_format: use external data format to store model which size is >= 2Gb.
        :param per_channel: whether to compute ranges per each channel.
        """
        ...
    
    def set_execution_providers(self, execution_providers=...): # -> None:
        """
        reset the execution providers to execute the collect_data. It triggers to re-creating inference session.
        """
        ...
    
    def create_inference_session(self): # -> None:
        """
        create an OnnxRuntime InferenceSession.
        """
        ...
    
    def select_tensors_to_calibrate(self, model: ModelProto): # -> tuple[set[Any], dict[Any, Any]]:
        """
        select input/output tensors of candidate nodes to calibrate.
        returns:
            tensors (set): set of tensor name.
            value_infos (dict): tensor name to value info.
        """
        ...
    
    def get_augment_model(self):
        """
        return: augmented onnx model. Call after calling augment_graph
        """
        ...
    
    def augment_graph(self):
        """
        abstract method: augment the input model to prepare for collecting data. It will:
            1. augment the model to be able to collect desired statistics data
            2. save augmented model to augmented_model_paths
        """
        ...
    
    def collect_data(self, data_reader: CalibrationDataReader):
        """
        abstract method: collect the tensors that will be used for range computation. It can be called multiple times.
        """
        ...
    
    def compute_data(self) -> TensorsData:
        """
        abstract method: compute data based on the calibration method stored in TensorsData
        """
        ...
    


class MinMaxCalibrater(CalibraterBase):
    def __init__(self, model_path: str | Path, op_types_to_calibrate: Sequence[str] | None = ..., augmented_model_path=..., symmetric=..., use_external_data_format=..., moving_average=..., averaging_constant=..., max_intermediate_outputs=..., per_channel=...) -> None:
        """
        :param model_path: ONNX model to calibrate. It is a model path
        :param op_types_to_calibrate: operator types to calibrate. By default, calibrate all the float32/float16 tensors.
        :param augmented_model_path: save augmented model to this path.
        :param symmetric: make range of tensor symmetric (central point is 0).
        :param use_external_data_format: use external data format to store model which size is >= 2Gb
        :param moving_average: compute the moving average of the minimum and maximum values instead of the global minimum and maximum.
        :param averaging_constant: constant smoothing factor to use when computing the moving average.
        :param max_intermediate_outputs: maximum number of intermediate outputs before an intermediate range is computed.
        :param per_channel: whether to compute ranges per each channel.
        """
        ...
    
    def augment_graph(self): # -> None:
        """
        Adds ReduceMin and ReduceMax nodes to all quantization_candidates op type nodes in
        model and ensures their outputs are stored as part of the graph output
        :return: augmented ONNX model
        """
        ...
    
    def clear_collected_data(self): # -> None:
        ...
    
    def collect_data(self, data_reader: CalibrationDataReader): # -> None:
        ...
    
    def merge_range(self, old_range, new_range):
        ...
    
    def compute_data(self) -> TensorsData:
        """
        Compute the min-max range of tensor
        :return: dictionary mapping: {added node names: (ReduceMin, ReduceMax) pairs }
        """
        ...
    


class HistogramCalibrater(CalibraterBase):
    def __init__(self, model_path: str | Path, op_types_to_calibrate: Sequence[str] | None = ..., augmented_model_path=..., use_external_data_format=..., method=..., symmetric=..., num_bins=..., num_quantized_bins=..., percentile=..., scenario=...) -> None:
        """
        :param model_path: ONNX model to calibrate. It is a model path.
        :param op_types_to_calibrate: operator types to calibrate. By default, calibrate all the float32/float16 tensors.
        :param augmented_model_path: save augmented model to this path.
        :param use_external_data_format: use external data format to store model which size is >= 2Gb
        :param method: A string. One of ['entropy', 'percentile'].
        :param symmetric: make range of tensor symmetric (central point is 0).
        :param num_bins: number of bins to create a new histogram for collecting tensor values.
        :param num_quantized_bins: number of quantized bins. Default 128.
        :param percentile: A float number between [0, 100]. Default 99.99.
        :param scenario: see :class:`DistributionCalibrater`
        """
        ...
    
    def augment_graph(self): # -> None:
        """
        make all quantization_candidates op type nodes as part of the graph output.
        :return: augmented ONNX model
        """
        ...
    
    def clear_collected_data(self): # -> None:
        ...
    
    def collect_data(self, data_reader: CalibrationDataReader): # -> None:
        """
        Entropy Calibrator collects operators' tensors as well as generates tensor histogram for each operator.
        """
        ...
    
    def compute_data(self) -> TensorsData:
        """
        Compute the min-max range of tensor
        :return: dictionary mapping: {tensor name: (min value, max value)}
        """
        ...
    


class EntropyCalibrater(HistogramCalibrater):
    def __init__(self, model_path: str | Path, op_types_to_calibrate: Sequence[str] | None = ..., augmented_model_path=..., use_external_data_format=..., method=..., symmetric=..., num_bins=..., num_quantized_bins=...) -> None:
        """
        :param model_path: ONNX model to calibrate. It is a model path
        :param op_types_to_calibrate: operator types to calibrate. By default, calibrate all the float32/float16 tensors.
        :param augmented_model_path: save augmented model to this path.
        :param use_external_data_format: use external data format to store model which size is >= 2Gb
        :param method: A string. One of ['entropy', 'percentile', 'distribution'].
        :param symmetric: make range of tensor symmetric (central point is 0).
        :param num_bins: number of bins to create a new histogram for collecting tensor values.
        :param num_quantized_bins: number of quantized bins. Default 128.
        """
        ...
    


class PercentileCalibrater(HistogramCalibrater):
    def __init__(self, model_path: str | Path, op_types_to_calibrate: Sequence[str] | None = ..., augmented_model_path=..., use_external_data_format=..., method=..., symmetric=..., num_bins=..., percentile=...) -> None:
        """
        :param model_path: ONNX model to calibrate. It is a model path
        :param op_types_to_calibrate: operator types to calibrate. By default, calibrate all the float32/float16 tensors.
        :param augmented_model_path: save augmented model to this path.
        :param use_external_data_format: use external data format to store model which size is >= 2Gb
        :param method: A string. One of ['entropy', 'percentile', 'distribution'].
        :param symmetric: make range of tensor symmetric (central point is 0).
        :param num_quantized_bins: number of quantized bins. Default 128.
        :param percentile: A float number between [0, 100]. Default 99.99.
        """
        ...
    


class DistributionCalibrater(HistogramCalibrater):
    def __init__(self, model_path: str | Path, op_types_to_calibrate: Sequence[str] | None = ..., augmented_model_path=..., use_external_data_format=..., method=..., num_bins=..., scenario=...) -> None:
        """
        :param model_path: ONNX model to calibrate. It is a model path
        :param op_types_to_calibrate: operator types to calibrate. By default, calibrate all the float32/float16 tensors.
        :param augmented_model_path: save augmented model to this path.
        :param use_external_data_format: use external data format to store model which size is >= 2Gb
        :param method: A string. One of ['entropy', 'percentile', 'distribution'].
        :param symmetric: make range of tensor symmetric (central point is 0).
        :param num_bins: number of bins to create a new histogram for collecting tensor values.
        :param scenario: for float 8 only, if `scenario="same"`,
            the algorithm weights and float 8 follow the same distribution,
            if `scenario="p3"`, it assumes the weights follow
            a gaussian law and float 8 ~ X^3 where X is a gaussian law
        """
        ...
    


class CalibrationDataCollector(metaclass=abc.ABCMeta):
    """
    Base class for collecting data for calibration-based quantization.
    """
    @abc.abstractmethod
    def collect(self, name_to_arr):
        """
        Generate informative data based on given data.
            name_to_arr : dict
                tensor name to NDArray data
        """
        ...
    
    @abc.abstractmethod
    def compute_collection_result(self):
        """
        Get the optimal result among collection data.
        """
        ...
    


class HistogramCollector(CalibrationDataCollector):
    """
    Collecting histogram for each tensor. Percentile and Entropy method are supported.

    ref: https://github.com//apache/incubator-mxnet/blob/master/python/mxnet/contrib/quantization.py
    ref: https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/_modules/
                 pytorch_quantization/calib/histogram.html
    """
    def __init__(self, method, symmetric, num_bins, num_quantized_bins, percentile, scenario) -> None:
        ...
    
    def get_histogram_dict(self): # -> dict[Any, Any]:
        ...
    
    def collect(self, name_to_arr): # -> None:
        ...
    
    def collect_absolute_value(self, name_to_arr): # -> None:
        """
        Collect histogram on absolute value
        """
        ...
    
    def collect_value(self, name_to_arr): # -> None:
        """
        Collect histogram on real value
        """
        ...
    
    def merge_histogram(self, old_histogram, data_arr, new_min, new_max, new_threshold): # -> tuple[Any, Any, Any, Any, Any] | tuple[Any | NDArray[Any], NDArray[Any], Any, Any, Any]:
        ...
    
    def compute_collection_result(self): # -> dict[Any, Any]:
        ...
    
    def compute_percentile(self): # -> dict[Any, Any]:
        ...
    
    def compute_entropy(self): # -> dict[Any, Any]:
        ...
    
    def compute_distribution(self): # -> dict[Any, Any]:
        ...
    
    def get_entropy_threshold(self, histogram, num_quantized_bins): # -> tuple[Any | NDArray[Any], Any] | tuple[Any, NDArray[Any]] | tuple[NDArray[Any], NDArray[Any]]:
        """Given a dataset, find the optimal threshold for quantizing it.
        The reference distribution is `q`, and the candidate distribution is `p`.
        `q` is a truncated version of the original distribution.
        Ref: http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf
        """
        ...
    


def create_calibrator(model: str | Path, op_types_to_calibrate: Sequence[str] | None = ..., augmented_model_path=..., calibrate_method=..., use_external_data_format=..., providers=..., extra_options=...): # -> MinMaxCalibrater | EntropyCalibrater | PercentileCalibrater | DistributionCalibrater:
    ...

